{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49af8e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "877f33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066325b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-3V2ROQ70:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Kishor</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x25852d05f90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Kishor').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d2b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+\n",
      "|  id|   name| age|salary|country|       dept|\n",
      "+----+-------+----+------+-------+-----------+\n",
      "|   1| manish|  26| 20000|  india|         IT|\n",
      "|   2|  rahul|NULL| 40000|germany|engineering|\n",
      "|   3|  pawan|  12| 60000|  india|      sales|\n",
      "|   4|roshini|  44|  NULL|     uk|engineering|\n",
      "|   5|raushan|  35| 70000|  india|      sales|\n",
      "|   6|   NULL|  29|200000|     uk|         IT|\n",
      "|   7|   adam|  37| 65000|     us|         IT|\n",
      "|   8|  chris|  16| 40000|     us|      sales|\n",
      "|NULL|   NULL|NULL|  NULL|   NULL|       NULL|\n",
      "|   7|   adam|  37| 65000|     us|         IT|\n",
      "+----+-------+----+------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_data = [\n",
    "(1,'manish',26,20000,'india','IT'),\n",
    "(2,'rahul',None,40000,'germany','engineering'),\n",
    "(3,'pawan',12,60000,'india','sales'),\n",
    "(4,'roshini',44,None,'uk','engineering'),\n",
    "(5,'raushan',35,70000,'india','sales'),\n",
    "(6,None,29,200000,'uk','IT'),\n",
    "(7,'adam',37,65000,'us','IT'),\n",
    "(8,'chris',16,40000,'us','sales'),\n",
    "(None,None,None,None,None,None),\n",
    "(7,'adam',37,65000,'us','IT')\n",
    "]\n",
    "m_schema = ['id','name','age','salary', 'country','dept']\n",
    "df = spark.createDataFrame(data = emp_data, schema=m_schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bcd8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "249bf15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(name)|\n",
      "+-----------+\n",
      "|          8|\n",
      "+-----------+\n",
      "\n",
      "+---------+\n",
      "|count(id)|\n",
      "+---------+\n",
      "|        9|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count('name')).show()\n",
    "df.select(count('id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab856637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      10|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count('*')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2500255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-----------+\n",
      "|sum_of_salary|max(salary)|min(salary)|\n",
      "+-------------+-----------+-----------+\n",
      "|       560000|     200000|      20000|\n",
      "+-------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(sum('salary').alias(\"sum_of_salary\"), max('salary'), min('salary')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff6222ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|sum_of_salary|avg_salary|\n",
      "+-------------+----------+\n",
      "|       560000|     70000|\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(sum('salary').alias(\"sum_of_salary\"), avg('salary').cast('int').alias('avg_salary')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03240a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "153625dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+---------+\n",
      "| id|   name|salary|     dept|\n",
      "+---+-------+------+---------+\n",
      "|  1| manish| 50000|       IT|\n",
      "|  2| vikash| 60000|    sales|\n",
      "|  3|raushan| 70000|marketing|\n",
      "|  4| mukesh| 80000|       IT|\n",
      "|  5| pritam| 90000|    sales|\n",
      "|  6| nikita| 45000|marketing|\n",
      "|  7| ragini| 55000|marketing|\n",
      "|  8| rakesh|100000|       IT|\n",
      "|  9| aditya| 65000|       IT|\n",
      "| 10|  rahul| 50000|marketing|\n",
      "+---+-------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1 = [(1,'manish',50000,'IT'),\n",
    "(2,'vikash',60000,'sales'),\n",
    "(3,'raushan',70000,'marketing'),\n",
    "(4,'mukesh',80000,'IT'),\n",
    "(5,'pritam',90000,'sales'),\n",
    "(6,'nikita',45000,'marketing'),\n",
    "(7,'ragini',55000,'marketing'),\n",
    "(8,'rakesh',100000,'IT'),\n",
    "(9,'aditya',65000,'IT'),\n",
    "(10,'rahul',50000,'marketing')]\n",
    "\n",
    "m_schema = ['id', 'name', 'salary', 'dept']\n",
    "df = spark.createDataFrame(data = data1, schema=m_schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c012e14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     dept|sum(salary)|\n",
      "+---------+-----------+\n",
      "|       IT|     295000|\n",
      "|    sales|     150000|\n",
      "|marketing|     220000|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('dept').agg(sum('salary')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaed6b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+---------+-------+\n",
      "| id|   name|salary|     dept|country|\n",
      "+---+-------+------+---------+-------+\n",
      "|  1| manish| 50000|       IT|  india|\n",
      "|  2| vikash| 60000|    sales|     us|\n",
      "|  3|raushan| 70000|marketing|  india|\n",
      "|  4| mukesh| 80000|       IT|     us|\n",
      "|  5| pritam| 90000|    sales|  india|\n",
      "|  6| nikita| 45000|marketing|     us|\n",
      "|  7| ragini| 55000|marketing|  india|\n",
      "|  8| rakesh|100000|       IT|     us|\n",
      "|  9| aditya| 65000|       IT|  india|\n",
      "| 10|  rahul| 50000|marketing|     us|\n",
      "+---+-------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2 = [(1,'manish',50000,'IT','india'),\n",
    "(2,'vikash',60000,'sales','us'),\n",
    "(3,'raushan',70000,'marketing','india'),\n",
    "(4,'mukesh',80000,'IT','us'),\n",
    "(5,'pritam',90000,'sales','india'),\n",
    "(6,'nikita',45000,'marketing','us'),\n",
    "(7,'ragini',55000,'marketing','india'),\n",
    "(8,'rakesh',100000,'IT','us'),\n",
    "(9,'aditya',65000,'IT','india'),\n",
    "(10,'rahul',50000,'marketing','us') ]\n",
    "\n",
    "m_schema1 = ['id', 'name', 'salary', 'dept', 'country']\n",
    "df1 = spark.createDataFrame(data = data2, schema=m_schema1)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2990ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----------+\n",
      "|     dept|country|sum(salary)|\n",
      "+---------+-------+-----------+\n",
      "|       IT|  india|     115000|\n",
      "|    sales|     us|      60000|\n",
      "|marketing|  india|     125000|\n",
      "|    sales|  india|      90000|\n",
      "|       IT|     us|     180000|\n",
      "|marketing|     us|      95000|\n",
      "+---------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy('dept', 'country').agg(sum('salary')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221f3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef635e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1aefc3f",
   "metadata": {},
   "source": [
    "# Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aedc82ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = [(1,'manish','patna',\"30-05-2022\"),\n",
    "(2,'vikash','kolkata',\"12-03-2023\"),\n",
    "(3,'nikita','delhi',\"25-06-2023\"),\n",
    "(4,'rahul','ranchi',\"24-03-2023\"),\n",
    "(5,'mahesh','jaipur',\"22-03-2023\"),\n",
    "(6,'prantosh','kolkata',\"18-10-2022\"),\n",
    "(7,'raman','patna',\"30-12-2022\"),\n",
    "(8,'prakash','ranchi',\"24-02-2023\"),\n",
    "(9,'ragini','kolkata',\"03-03-2023\"),\n",
    "(10,'raushan','jaipur',\"05-02-2023\")]\n",
    "\n",
    "\n",
    "customer_schema=['customer_id','customer_name','address','date_of_joining']\n",
    "customer_df = spark.createDataFrame(data= customer_data, schema = customer_schema)\n",
    "\n",
    "sales_data = [(1,22,10,\"01-06-2022\"),\n",
    "(1,27,5,\"03-02-2023\"),\n",
    "(2,5,3,\"01-06-2023\"),\n",
    "(5,22,1,\"22-03-2023\"),\n",
    "(7,22,4,\"03-02-2023\"),\n",
    "(9,5,6,\"03-03-2023\"),\n",
    "(2,1,12,\"15-06-2023\"),\n",
    "(1,56,2,\"25-06-2023\"),\n",
    "(5,12,5,\"15-04-2023\"),\n",
    "(11,12,76,\"12-03-2023\")]\n",
    "\n",
    "sales_schema=['customer_id','product_id','quantity','date_of_purchase']\n",
    "sales_df = spark.createDataFrame(data= sales_data, schema = sales_schema)\n",
    "\n",
    "product_data = [(1, 'fanta',20),\n",
    "(2, 'dew',22),\n",
    "(5, 'sprite',40),\n",
    "(7, 'redbull',100),\n",
    "(12,'mazza',45),\n",
    "(22,'coke',27),\n",
    "(25,'limca',21),\n",
    "(27,'pepsi',14),\n",
    "(56,'sting',10)]\n",
    "\n",
    "product_schema=['id','name','price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ccdcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+\n",
      "|customer_id|customer_name|address|date_of_joining|\n",
      "+-----------+-------------+-------+---------------+\n",
      "|          1|       manish|  patna|     30-05-2022|\n",
      "|          2|       vikash|kolkata|     12-03-2023|\n",
      "|          3|       nikita|  delhi|     25-06-2023|\n",
      "|          4|        rahul| ranchi|     24-03-2023|\n",
      "|          5|       mahesh| jaipur|     22-03-2023|\n",
      "|          6|     prantosh|kolkata|     18-10-2022|\n",
      "|          7|        raman|  patna|     30-12-2022|\n",
      "|          8|      prakash| ranchi|     24-02-2023|\n",
      "|          9|       ragini|kolkata|     03-03-2023|\n",
      "|         10|      raushan| jaipur|     05-02-2023|\n",
      "+-----------+-------------+-------+---------------+\n",
      "\n",
      "+-----------+----------+--------+----------------+\n",
      "|customer_id|product_id|quantity|date_of_purchase|\n",
      "+-----------+----------+--------+----------------+\n",
      "|          1|        22|      10|      01-06-2022|\n",
      "|          1|        27|       5|      03-02-2023|\n",
      "|          2|         5|       3|      01-06-2023|\n",
      "|          5|        22|       1|      22-03-2023|\n",
      "|          7|        22|       4|      03-02-2023|\n",
      "|          9|         5|       6|      03-03-2023|\n",
      "|          2|         1|      12|      15-06-2023|\n",
      "|          1|        56|       2|      25-06-2023|\n",
      "|          5|        12|       5|      15-04-2023|\n",
      "|         11|        12|      76|      12-03-2023|\n",
      "+-----------+----------+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.show()\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "742865e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n",
      "|customer_id|customer_name|address|date_of_joining|customer_id|product_id|quantity|date_of_purchase|\n",
      "+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n",
      "|          1|       manish|  patna|     30-05-2022|          1|        22|      10|      01-06-2022|\n",
      "|          1|       manish|  patna|     30-05-2022|          1|        27|       5|      03-02-2023|\n",
      "|          1|       manish|  patna|     30-05-2022|          1|        56|       2|      25-06-2023|\n",
      "|          2|       vikash|kolkata|     12-03-2023|          2|         5|       3|      01-06-2023|\n",
      "|          2|       vikash|kolkata|     12-03-2023|          2|         1|      12|      15-06-2023|\n",
      "|          5|       mahesh| jaipur|     22-03-2023|          5|        22|       1|      22-03-2023|\n",
      "|          5|       mahesh| jaipur|     22-03-2023|          5|        12|       5|      15-04-2023|\n",
      "|          7|        raman|  patna|     30-12-2022|          7|        22|       4|      03-02-2023|\n",
      "|          9|       ragini|kolkata|     03-03-2023|          9|         5|       6|      03-03-2023|\n",
      "+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.join(sales_df, sales_df['customer_id'] == customer_df['customer_id'], 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b1eff5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|customer_id|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          2|\n",
      "|          2|\n",
      "|          5|\n",
      "|          5|\n",
      "|          7|\n",
      "|          9|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.join(sales_df, sales_df['customer_id'] == customer_df['customer_id'], 'inner')\\\n",
    ".select(sales_df['customer_id']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1560b",
   "metadata": {},
   "source": [
    "# Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cbd235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ebe0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+\n",
      "| id|    name|salary|     dept|gender|\n",
      "+---+--------+------+---------+------+\n",
      "|  1|  manish| 50000|       IT|     m|\n",
      "|  2|  vikash| 60000|    sales|     m|\n",
      "|  3| raushan| 70000|marketing|     m|\n",
      "|  4|  mukesh| 80000|       IT|     m|\n",
      "|  5|   priti| 90000|    sales|     f|\n",
      "|  6|  nikita| 45000|marketing|     f|\n",
      "|  7|  ragini| 55000|marketing|     f|\n",
      "|  8|   rashi|100000|       IT|     f|\n",
      "|  9|  aditya| 65000|       IT|     m|\n",
      "| 10|   rahul| 50000|marketing|     m|\n",
      "| 11|   rakhi| 50000|       IT|     f|\n",
      "| 12|akhilesh| 90000|    sales|     m|\n",
      "+---+--------+------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_data = [(1,'manish',50000,'IT','m'),\n",
    "(2,'vikash',60000,'sales','m'),\n",
    "(3,'raushan',70000,'marketing','m'),\n",
    "(4,'mukesh',80000,'IT','m'),\n",
    "(5,'priti',90000,'sales','f'),\n",
    "(6,'nikita',45000,'marketing','f'),\n",
    "(7,'ragini',55000,'marketing','f'),\n",
    "(8,'rashi',100000,'IT','f'),\n",
    "(9,'aditya',65000,'IT','m'),\n",
    "(10,'rahul',50000,'marketing','m'),\n",
    "(11,'rakhi',50000,'IT','f'),\n",
    "(12,'akhilesh',90000,'sales','m')]\n",
    "\n",
    "m_schema = ['id','name','salary','dept','gender']\n",
    "df= spark.createDataFrame(data=emp_data, schema = m_schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "590c1167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+----------+---+----------+\n",
      "|id |name    |salary|dept     |gender|row_number|row|dense_rank|\n",
      "+---+--------+------+---------+------+----------+---+----------+\n",
      "|1  |manish  |50000 |IT       |m     |1         |1  |1         |\n",
      "|11 |rakhi   |50000 |IT       |f     |2         |1  |1         |\n",
      "|9  |aditya  |65000 |IT       |m     |3         |3  |2         |\n",
      "|4  |mukesh  |80000 |IT       |m     |4         |4  |3         |\n",
      "|8  |rashi   |100000|IT       |f     |5         |5  |4         |\n",
      "|6  |nikita  |45000 |marketing|f     |1         |1  |1         |\n",
      "|10 |rahul   |50000 |marketing|m     |2         |2  |2         |\n",
      "|7  |ragini  |55000 |marketing|f     |3         |3  |3         |\n",
      "|3  |raushan |70000 |marketing|m     |4         |4  |4         |\n",
      "|2  |vikash  |60000 |sales    |m     |1         |1  |1         |\n",
      "|5  |priti   |90000 |sales    |f     |2         |2  |2         |\n",
      "|12 |akhilesh|90000 |sales    |m     |3         |2  |2         |\n",
      "+---+--------+------+---------+------+----------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy('dept').orderBy('salary')\n",
    "\n",
    "df.withColumn('row_number', row_number().over(window))\\\n",
    ".withColumn('row', rank().over(window))\\\n",
    ".withColumn('dense_rank', dense_rank().over(window)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76582f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+----------+---+----------+\n",
      "|id |name    |salary|dept     |gender|row_number|row|dense_rank|\n",
      "+---+--------+------+---------+------+----------+---+----------+\n",
      "|11 |rakhi   |50000 |IT       |f     |1         |1  |1         |\n",
      "|8  |rashi   |100000|IT       |f     |2         |2  |2         |\n",
      "|1  |manish  |50000 |IT       |m     |1         |1  |1         |\n",
      "|9  |aditya  |65000 |IT       |m     |2         |2  |2         |\n",
      "|4  |mukesh  |80000 |IT       |m     |3         |3  |3         |\n",
      "|6  |nikita  |45000 |marketing|f     |1         |1  |1         |\n",
      "|7  |ragini  |55000 |marketing|f     |2         |2  |2         |\n",
      "|10 |rahul   |50000 |marketing|m     |1         |1  |1         |\n",
      "|3  |raushan |70000 |marketing|m     |2         |2  |2         |\n",
      "|5  |priti   |90000 |sales    |f     |1         |1  |1         |\n",
      "|2  |vikash  |60000 |sales    |m     |1         |1  |1         |\n",
      "|12 |akhilesh|90000 |sales    |m     |2         |2  |2         |\n",
      "+---+--------+------+---------+------+----------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy('dept','gender').orderBy('salary')\n",
    "\n",
    "df.withColumn('row_number', row_number().over(window))\\\n",
    ".withColumn('row', rank().over(window))\\\n",
    ".withColumn('dense_rank', dense_rank().over(window)).show(truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "954c942f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+----------+---+----------+\n",
      "|id |name    |salary|dept     |gender|row_number|row|dense_rank|\n",
      "+---+--------+------+---------+------+----------+---+----------+\n",
      "|8  |rashi   |100000|IT       |f     |1         |1  |1         |\n",
      "|4  |mukesh  |80000 |IT       |m     |2         |2  |2         |\n",
      "|3  |raushan |70000 |marketing|m     |1         |1  |1         |\n",
      "|7  |ragini  |55000 |marketing|f     |2         |2  |2         |\n",
      "|5  |priti   |90000 |sales    |f     |1         |1  |1         |\n",
      "|12 |akhilesh|90000 |sales    |m     |2         |1  |1         |\n",
      "|2  |vikash  |60000 |sales    |m     |3         |3  |2         |\n",
      "+---+--------+------+---------+------+----------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy('dept').orderBy(desc('salary'))\n",
    "df.withColumn('row_number', row_number().over(window))\\\n",
    ".withColumn('row', rank().over(window))\\\n",
    ".withColumn('dense_rank', dense_rank().over(window))\\\n",
    ".filter(col('dense_rank') <= 2).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0415c0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c189362",
   "metadata": {},
   "source": [
    "# lead and lag in spark | window function in pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3323a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+\n",
      "|product_id|product_name|sales_date|  sales|\n",
      "+----------+------------+----------+-------+\n",
      "|         1|      iphone|01-01-2023|1500000|\n",
      "|         2|     samsung|01-01-2023|1100000|\n",
      "|         3|     oneplus|01-01-2023|1100000|\n",
      "|         1|      iphone|01-02-2023|1300000|\n",
      "|         2|     samsung|01-02-2023|1120000|\n",
      "|         3|     oneplus|01-02-2023|1120000|\n",
      "|         1|      iphone|01-03-2023|1600000|\n",
      "|         2|     samsung|01-03-2023|1080000|\n",
      "|         3|     oneplus|01-03-2023|1160000|\n",
      "|         1|      iphone|01-04-2023|1700000|\n",
      "|         2|     samsung|01-04-2023|1800000|\n",
      "|         3|     oneplus|01-04-2023|1170000|\n",
      "|         1|      iphone|01-05-2023|1200000|\n",
      "|         2|     samsung|01-05-2023| 980000|\n",
      "|         3|     oneplus|01-05-2023|1175000|\n",
      "|         1|      iphone|01-06-2023|1100000|\n",
      "|         2|     samsung|01-06-2023|1100000|\n",
      "|         3|     oneplus|01-06-2023|1200000|\n",
      "+----------+------------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_data = [\n",
    "(1,\"iphone\",\"01-01-2023\",1500000),\n",
    "(2,\"samsung\",\"01-01-2023\",1100000),\n",
    "(3,\"oneplus\",\"01-01-2023\",1100000),\n",
    "(1,\"iphone\",\"01-02-2023\",1300000),\n",
    "(2,\"samsung\",\"01-02-2023\",1120000),\n",
    "(3,\"oneplus\",\"01-02-2023\",1120000),\n",
    "(1,\"iphone\",\"01-03-2023\",1600000),\n",
    "(2,\"samsung\",\"01-03-2023\",1080000),\n",
    "(3,\"oneplus\",\"01-03-2023\",1160000),\n",
    "(1,\"iphone\",\"01-04-2023\",1700000),\n",
    "(2,\"samsung\",\"01-04-2023\",1800000),\n",
    "(3,\"oneplus\",\"01-04-2023\",1170000),\n",
    "(1,\"iphone\",\"01-05-2023\",1200000),\n",
    "(2,\"samsung\",\"01-05-2023\",980000),\n",
    "(3,\"oneplus\",\"01-05-2023\",1175000),\n",
    "(1,\"iphone\",\"01-06-2023\",1100000),\n",
    "(2,\"samsung\",\"01-06-2023\",1100000),\n",
    "(3,\"oneplus\",\"01-06-2023\",1200000)\n",
    "]\n",
    "col_n = ['product_id','product_name', 'sales_date', 'sales']\n",
    "df = spark.createDataFrame(data=product_data, schema = col_n)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92cf279b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+--------------------+\n",
      "|product_id|product_name|sales_date|  sales|previous_month_sales|\n",
      "+----------+------------+----------+-------+--------------------+\n",
      "|         1|      iphone|01-01-2023|1500000|                NULL|\n",
      "|         1|      iphone|01-02-2023|1300000|             1500000|\n",
      "|         1|      iphone|01-03-2023|1600000|             1300000|\n",
      "|         1|      iphone|01-04-2023|1700000|             1600000|\n",
      "|         1|      iphone|01-05-2023|1200000|             1700000|\n",
      "|         1|      iphone|01-06-2023|1100000|             1200000|\n",
      "|         2|     samsung|01-01-2023|1100000|                NULL|\n",
      "|         2|     samsung|01-02-2023|1120000|             1100000|\n",
      "|         2|     samsung|01-03-2023|1080000|             1120000|\n",
      "|         2|     samsung|01-04-2023|1800000|             1080000|\n",
      "|         2|     samsung|01-05-2023| 980000|             1800000|\n",
      "|         2|     samsung|01-06-2023|1100000|              980000|\n",
      "|         3|     oneplus|01-01-2023|1100000|                NULL|\n",
      "|         3|     oneplus|01-02-2023|1120000|             1100000|\n",
      "|         3|     oneplus|01-03-2023|1160000|             1120000|\n",
      "|         3|     oneplus|01-04-2023|1170000|             1160000|\n",
      "|         3|     oneplus|01-05-2023|1175000|             1170000|\n",
      "|         3|     oneplus|01-06-2023|1200000|             1175000|\n",
      "+----------+------------+----------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy('product_id').orderBy('sales_date')\n",
    "last_month_df =df.withColumn('previous_month_sales', lag(col('sales'),1).over(window))\n",
    "last_month_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61fe5b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+--------------------+-------------+\n",
      "|product_id|product_name|sales_date|  sales|previous_month_sales|per_loss_gain|\n",
      "+----------+------------+----------+-------+--------------------+-------------+\n",
      "|         1|      iphone|01-01-2023|1500000|                NULL|         NULL|\n",
      "|         1|      iphone|01-02-2023|1300000|             1500000|      -200000|\n",
      "|         1|      iphone|01-03-2023|1600000|             1300000|       300000|\n",
      "|         1|      iphone|01-04-2023|1700000|             1600000|       100000|\n",
      "|         1|      iphone|01-05-2023|1200000|             1700000|      -500000|\n",
      "|         1|      iphone|01-06-2023|1100000|             1200000|      -100000|\n",
      "|         2|     samsung|01-01-2023|1100000|                NULL|         NULL|\n",
      "|         2|     samsung|01-02-2023|1120000|             1100000|        20000|\n",
      "|         2|     samsung|01-03-2023|1080000|             1120000|       -40000|\n",
      "|         2|     samsung|01-04-2023|1800000|             1080000|       720000|\n",
      "|         2|     samsung|01-05-2023| 980000|             1800000|      -820000|\n",
      "|         2|     samsung|01-06-2023|1100000|              980000|       120000|\n",
      "|         3|     oneplus|01-01-2023|1100000|                NULL|         NULL|\n",
      "|         3|     oneplus|01-02-2023|1120000|             1100000|        20000|\n",
      "|         3|     oneplus|01-03-2023|1160000|             1120000|        40000|\n",
      "|         3|     oneplus|01-04-2023|1170000|             1160000|        10000|\n",
      "|         3|     oneplus|01-05-2023|1175000|             1170000|         5000|\n",
      "|         3|     oneplus|01-06-2023|1200000|             1175000|        25000|\n",
      "+----------+------------+----------+-------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate loss \n",
    " \n",
    "last_month_df.withColumn('per_loss_gain', col('sales')-col('previous_month_sales')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66a5c6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+--------------------+-------------+\n",
      "|product_id|product_name|sales_date|  sales|previous_month_sales|per_loss_gain|\n",
      "+----------+------------+----------+-------+--------------------+-------------+\n",
      "|         1|      iphone|01-01-2023|1500000|                NULL|         NULL|\n",
      "|         1|      iphone|01-02-2023|1300000|             1500000|       -15.38|\n",
      "|         1|      iphone|01-03-2023|1600000|             1300000|        18.75|\n",
      "|         1|      iphone|01-04-2023|1700000|             1600000|         5.88|\n",
      "|         1|      iphone|01-05-2023|1200000|             1700000|       -41.67|\n",
      "|         1|      iphone|01-06-2023|1100000|             1200000|        -9.09|\n",
      "|         2|     samsung|01-01-2023|1100000|                NULL|         NULL|\n",
      "|         2|     samsung|01-02-2023|1120000|             1100000|         1.79|\n",
      "|         2|     samsung|01-03-2023|1080000|             1120000|         -3.7|\n",
      "|         2|     samsung|01-04-2023|1800000|             1080000|         40.0|\n",
      "|         2|     samsung|01-05-2023| 980000|             1800000|       -83.67|\n",
      "|         2|     samsung|01-06-2023|1100000|              980000|        10.91|\n",
      "|         3|     oneplus|01-01-2023|1100000|                NULL|         NULL|\n",
      "|         3|     oneplus|01-02-2023|1120000|             1100000|         1.79|\n",
      "|         3|     oneplus|01-03-2023|1160000|             1120000|         3.45|\n",
      "|         3|     oneplus|01-04-2023|1170000|             1160000|         0.85|\n",
      "|         3|     oneplus|01-05-2023|1175000|             1170000|         0.43|\n",
      "|         3|     oneplus|01-06-2023|1200000|             1175000|         2.08|\n",
      "+----------+------------+----------+-------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate percent & round off\n",
    "\n",
    "last_month_df.withColumn('per_loss_gain', round(((col('sales')-col('previous_month_sales'))/col('sales'))*100,2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d42d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf30294a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+--------------------+\n",
      "|product_id|product_name|sales_date|  sales|previous_month_sales|\n",
      "+----------+------------+----------+-------+--------------------+\n",
      "|         1|      iphone|01-01-2023|1500000|             1300000|\n",
      "|         1|      iphone|01-02-2023|1300000|             1600000|\n",
      "|         1|      iphone|01-03-2023|1600000|             1700000|\n",
      "|         1|      iphone|01-04-2023|1700000|             1200000|\n",
      "|         1|      iphone|01-05-2023|1200000|             1100000|\n",
      "|         1|      iphone|01-06-2023|1100000|                NULL|\n",
      "|         2|     samsung|01-01-2023|1100000|             1120000|\n",
      "|         2|     samsung|01-02-2023|1120000|             1080000|\n",
      "|         2|     samsung|01-03-2023|1080000|             1800000|\n",
      "|         2|     samsung|01-04-2023|1800000|              980000|\n",
      "|         2|     samsung|01-05-2023| 980000|             1100000|\n",
      "|         2|     samsung|01-06-2023|1100000|                NULL|\n",
      "|         3|     oneplus|01-01-2023|1100000|             1120000|\n",
      "|         3|     oneplus|01-02-2023|1120000|             1160000|\n",
      "|         3|     oneplus|01-03-2023|1160000|             1170000|\n",
      "|         3|     oneplus|01-04-2023|1170000|             1175000|\n",
      "|         3|     oneplus|01-05-2023|1175000|             1200000|\n",
      "|         3|     oneplus|01-06-2023|1200000|                NULL|\n",
      "+----------+------------+----------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy('product_id').orderBy('sales_date')\n",
    "last_month_df =df.withColumn('previous_month_sales', lead(col('sales'),1).over(window))\n",
    "last_month_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7924d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b453aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11c7af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+---------+\n",
      "| id|    name|salary|gender|     dept|\n",
      "+---+--------+------+------+---------+\n",
      "|  1|  manish| 50000|     m|       IT|\n",
      "|  2|  vikash| 60000|     m|    sales|\n",
      "|  3| raushan| 70000|     m|marketing|\n",
      "|  4|  mukesh| 80000|     m|       IT|\n",
      "|  5|   priti| 90000|     f|    sales|\n",
      "|  6|  nikita| 45000|     f|marketing|\n",
      "|  7|  ragini| 55000|     f|marketing|\n",
      "|  8|   rashi|100000|     f|       IT|\n",
      "|  9|  aditya| 65000|     m|       IT|\n",
      "| 10|   rahul| 50000|     m|marketing|\n",
      "| 11|   rakhi| 50000|     f|       IT|\n",
      "| 12|akhilesh| 90000|     m|    sales|\n",
      "+---+--------+------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_data = [(1,'manish',50000,'IT','m'),\n",
    "(2,'vikash',60000,'sales','m'),\n",
    "(3,'raushan',70000,'marketing','m'),\n",
    "(4,'mukesh',80000,'IT','m'),\n",
    "(5,'priti',90000,'sales','f'),\n",
    "(6,'nikita',45000,'marketing','f'),\n",
    "(7,'ragini',55000,'marketing','f'),\n",
    "(8,'rashi',100000,'IT','f'),\n",
    "(9,'aditya',65000,'IT','m'),\n",
    "(10,'rahul',50000,'marketing','m'),\n",
    "(11,'rakhi',50000,'IT','f'),\n",
    "(12,'akhilesh',90000,'sales','m')]\n",
    "\n",
    "emp_schema=['id','name','salary','dept','gender']\n",
    "\n",
    "emp_df = spark.createDataFrame(data=emp_data,schema=emp_schema)\n",
    "emp_df = emp_df.select('id','name','salary','gender','dept')\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1b49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b26390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bde93899",
   "metadata": {},
   "source": [
    "# Range and row between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcee2407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+\n",
      "|product_id|product_name|sales_date|  sales|\n",
      "+----------+------------+----------+-------+\n",
      "|         2|     samsung|01-01-1995|  11000|\n",
      "|         1|      iphone|01-02-2023|1300000|\n",
      "|         2|     samsung|01-02-2023|1120000|\n",
      "|         3|     oneplus|01-02-2023|1120000|\n",
      "|         1|      iphone|01-03-2023|1600000|\n",
      "|         2|     samsung|01-03-2023|1080000|\n",
      "|         3|     oneplus|01-03-2023|1160000|\n",
      "|         1|      iphone|01-01-2006|  15000|\n",
      "|         1|      iphone|01-04-2023|1700000|\n",
      "|         2|     samsung|01-04-2023|1800000|\n",
      "|         3|     oneplus|01-04-2023|1170000|\n",
      "|         1|      iphone|01-05-2023|1200000|\n",
      "|         2|     samsung|01-05-2023| 980000|\n",
      "|         3|     oneplus|01-05-2023|1175000|\n",
      "|         1|      iphone|01-06-2023|1100000|\n",
      "|         3|     oneplus|01-01-2010|  23000|\n",
      "|         2|     samsung|01-06-2023|1100000|\n",
      "|         3|     oneplus|01-06-2023|1200000|\n",
      "+----------+------------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_data = [\n",
    "(2,\"samsung\",\"01-01-1995\",11000),\n",
    "(1,\"iphone\",\"01-02-2023\",1300000),\n",
    "(2,\"samsung\",\"01-02-2023\",1120000),\n",
    "(3,\"oneplus\",\"01-02-2023\",1120000),\n",
    "(1,\"iphone\",\"01-03-2023\",1600000),\n",
    "(2,\"samsung\",\"01-03-2023\",1080000),\n",
    "(3,\"oneplus\",\"01-03-2023\",1160000),\n",
    "(1,\"iphone\",\"01-01-2006\",15000),\n",
    "(1,\"iphone\",\"01-04-2023\",1700000),\n",
    "(2,\"samsung\",\"01-04-2023\",1800000),\n",
    "(3,\"oneplus\",\"01-04-2023\",1170000),\n",
    "(1,\"iphone\",\"01-05-2023\",1200000),\n",
    "(2,\"samsung\",\"01-05-2023\",980000),\n",
    "(3,\"oneplus\",\"01-05-2023\",1175000),\n",
    "(1,\"iphone\",\"01-06-2023\",1100000),\n",
    "(3,\"oneplus\",\"01-01-2010\",23000),\n",
    "(2,\"samsung\",\"01-06-2023\",1100000),\n",
    "(3,\"oneplus\",\"01-06-2023\",1200000)\n",
    "]\n",
    "ms = ['product_id', 'product_name', 'sales_date', 'sales']\n",
    "rgdf = spark.createDataFrame(data = product_data, schema = ms)\n",
    "rgdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d237d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy('product_id').orderBy('sales_date')\\\n",
    "       .rowsBetween(Window.unboundedPreceding,Window.unboundedFollowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fff4da3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+-----------+------------+\n",
      "|product_id|product_name|sales_date|  sales|first_sales|latest_sales|\n",
      "+----------+------------+----------+-------+-----------+------------+\n",
      "|         1|      iphone|01-01-2006|  15000|      15000|     1100000|\n",
      "|         1|      iphone|01-02-2023|1300000|      15000|     1100000|\n",
      "|         1|      iphone|01-03-2023|1600000|      15000|     1100000|\n",
      "|         1|      iphone|01-04-2023|1700000|      15000|     1100000|\n",
      "|         1|      iphone|01-05-2023|1200000|      15000|     1100000|\n",
      "|         1|      iphone|01-06-2023|1100000|      15000|     1100000|\n",
      "|         2|     samsung|01-01-1995|  11000|      11000|     1100000|\n",
      "|         2|     samsung|01-02-2023|1120000|      11000|     1100000|\n",
      "|         2|     samsung|01-03-2023|1080000|      11000|     1100000|\n",
      "|         2|     samsung|01-04-2023|1800000|      11000|     1100000|\n",
      "|         2|     samsung|01-05-2023| 980000|      11000|     1100000|\n",
      "|         2|     samsung|01-06-2023|1100000|      11000|     1100000|\n",
      "|         3|     oneplus|01-01-2010|  23000|      23000|     1200000|\n",
      "|         3|     oneplus|01-02-2023|1120000|      23000|     1200000|\n",
      "|         3|     oneplus|01-03-2023|1160000|      23000|     1200000|\n",
      "|         3|     oneplus|01-04-2023|1170000|      23000|     1200000|\n",
      "|         3|     oneplus|01-05-2023|1175000|      23000|     1200000|\n",
      "|         3|     oneplus|01-06-2023|1200000|      23000|     1200000|\n",
      "+----------+------------+----------+-------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rgdf.withColumn('first_sales', first('sales').over(window))\\\n",
    "    .withColumn('latest_sales', last('sales').over(window)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e66b0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different & distinct ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39577dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+-----+\n",
      "| id|  name|      date| time|\n",
      "+---+------+----------+-----+\n",
      "|  1|manish|11-07-2023|10:20|\n",
      "|  1|manish|11-07-2023|11:20|\n",
      "|  2|rajesh|11-07-2023|11:20|\n",
      "|  1|manish|11-07-2023|11:50|\n",
      "|  2|rajesh|11-07-2023|13:20|\n",
      "|  1|manish|11-07-2023|19:20|\n",
      "|  2|rajesh|11-07-2023|17:20|\n",
      "|  1|manish|12-07-2023|10:32|\n",
      "|  1|manish|12-07-2023|12:20|\n",
      "|  3|vikash|12-07-2023|09:12|\n",
      "|  1|manish|12-07-2023|16:23|\n",
      "|  3|vikash|12-07-2023|18:08|\n",
      "+---+------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_data = [(1,\"manish\",\"11-07-2023\",\"10:20\"),\n",
    "        (1,\"manish\",\"11-07-2023\",\"11:20\"),\n",
    "        (2,\"rajesh\",\"11-07-2023\",\"11:20\"),\n",
    "        (1,\"manish\",\"11-07-2023\",\"11:50\"),\n",
    "        (2,\"rajesh\",\"11-07-2023\",\"13:20\"),\n",
    "        (1,\"manish\",\"11-07-2023\",\"19:20\"),\n",
    "        (2,\"rajesh\",\"11-07-2023\",\"17:20\"),\n",
    "        (1,\"manish\",\"12-07-2023\",\"10:32\"),\n",
    "        (1,\"manish\",\"12-07-2023\",\"12:20\"),\n",
    "        (3,\"vikash\",\"12-07-2023\",\"09:12\"),\n",
    "        (1,\"manish\",\"12-07-2023\",\"16:23\"),\n",
    "        (3,\"vikash\",\"12-07-2023\",\"18:08\")]\n",
    "\n",
    "emp_schema = [\"id\", \"name\", \"date\", \"time\"]\n",
    "emp_df = spark.createDataFrame(data=emp_data, schema=emp_schema)\n",
    "\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "648dc728",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = emp_df.withColumn('timestamp', \n",
    "                          from_unixtime(unix_timestamp(expr(\"concat(date,' ',time)\"), \"dd-MM-yyy HH:mm\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9539c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+-----+-------------------+\n",
      "| id|  name|      date| time|          timestamp|\n",
      "+---+------+----------+-----+-------------------+\n",
      "|  1|manish|11-07-2023|10:20|2023-07-11 10:20:00|\n",
      "|  1|manish|11-07-2023|11:20|2023-07-11 11:20:00|\n",
      "|  2|rajesh|11-07-2023|11:20|2023-07-11 11:20:00|\n",
      "|  1|manish|11-07-2023|11:50|2023-07-11 11:50:00|\n",
      "|  2|rajesh|11-07-2023|13:20|2023-07-11 13:20:00|\n",
      "|  1|manish|11-07-2023|19:20|2023-07-11 19:20:00|\n",
      "|  2|rajesh|11-07-2023|17:20|2023-07-11 17:20:00|\n",
      "|  1|manish|12-07-2023|10:32|2023-07-12 10:32:00|\n",
      "|  1|manish|12-07-2023|12:20|2023-07-12 12:20:00|\n",
      "|  3|vikash|12-07-2023|09:12|2023-07-12 09:12:00|\n",
      "|  1|manish|12-07-2023|16:23|2023-07-12 16:23:00|\n",
      "|  3|vikash|12-07-2023|18:08|2023-07-12 18:08:00|\n",
      "+---+------+----------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "abbecdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy('id','date').orderBy('date').rowsBetween(Window.unboundedPreceding,Window.unboundedFollowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d5b593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+-----+-------------------+-------------------+-------------------+--------------------+\n",
      "| id|  name|      date| time|          timestamp|              login|             logout|          total_time|\n",
      "+---+------+----------+-----+-------------------+-------------------+-------------------+--------------------+\n",
      "|  1|manish|11-07-2023|10:20|2023-07-11 10:20:00|2023-07-11 10:20:00|2023-07-11 19:20:00|INTERVAL '0 09:00...|\n",
      "|  1|manish|11-07-2023|11:20|2023-07-11 11:20:00|2023-07-11 10:20:00|2023-07-11 19:20:00|INTERVAL '0 09:00...|\n",
      "|  1|manish|11-07-2023|11:50|2023-07-11 11:50:00|2023-07-11 10:20:00|2023-07-11 19:20:00|INTERVAL '0 09:00...|\n",
      "|  1|manish|11-07-2023|19:20|2023-07-11 19:20:00|2023-07-11 10:20:00|2023-07-11 19:20:00|INTERVAL '0 09:00...|\n",
      "|  1|manish|12-07-2023|10:32|2023-07-12 10:32:00|2023-07-12 10:32:00|2023-07-12 16:23:00|INTERVAL '0 05:51...|\n",
      "|  1|manish|12-07-2023|12:20|2023-07-12 12:20:00|2023-07-12 10:32:00|2023-07-12 16:23:00|INTERVAL '0 05:51...|\n",
      "|  1|manish|12-07-2023|16:23|2023-07-12 16:23:00|2023-07-12 10:32:00|2023-07-12 16:23:00|INTERVAL '0 05:51...|\n",
      "|  2|rajesh|11-07-2023|11:20|2023-07-11 11:20:00|2023-07-11 11:20:00|2023-07-11 17:20:00|INTERVAL '0 06:00...|\n",
      "|  2|rajesh|11-07-2023|13:20|2023-07-11 13:20:00|2023-07-11 11:20:00|2023-07-11 17:20:00|INTERVAL '0 06:00...|\n",
      "|  2|rajesh|11-07-2023|17:20|2023-07-11 17:20:00|2023-07-11 11:20:00|2023-07-11 17:20:00|INTERVAL '0 06:00...|\n",
      "|  3|vikash|12-07-2023|09:12|2023-07-12 09:12:00|2023-07-12 09:12:00|2023-07-12 18:08:00|INTERVAL '0 08:56...|\n",
      "|  3|vikash|12-07-2023|18:08|2023-07-12 18:08:00|2023-07-12 09:12:00|2023-07-12 18:08:00|INTERVAL '0 08:56...|\n",
      "+---+------+----------+-----+-------------------+-------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = emp_df.withColumn('login', first(\"timestamp\").over(window))\\\n",
    "        .withColumn('logout', last('timestamp').over(window))\\\n",
    "        .withColumn('login',to_timestamp('login', 'yyyy-MM-dd HH:mm:ss'))\\\n",
    "        .withColumn('logout', to_timestamp('logout', 'yyyy-MM-dd HH:mm:ss'))\\\n",
    "        .withColumn('total_time', col('logout')-col('login')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf8fb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c1ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2833662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-----+\n",
      "|product_id|product_name|sales_date|sales|\n",
      "+----------+------------+----------+-----+\n",
      "|         1|      manish|11-07-2023|10:20|\n",
      "|         1|      manish|11-07-2023|11:20|\n",
      "|         2|      rajesh|11-07-2023|11:20|\n",
      "|         1|      manish|11-07-2023|11:50|\n",
      "|         2|      rajesh|11-07-2023|13:20|\n",
      "|         1|      manish|11-07-2023|19:20|\n",
      "|         2|      rajesh|11-07-2023|17:20|\n",
      "|         1|      manish|12-07-2023|10:32|\n",
      "|         1|      manish|12-07-2023|12:20|\n",
      "|         3|      vikash|12-07-2023|09:12|\n",
      "|         1|      manish|12-07-2023|16:23|\n",
      "|         3|      vikash|12-07-2023|18:08|\n",
      "+----------+------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_data = [\n",
    "(1,\"iphone\",\"01-01-2023\",1500000),\n",
    "(2,\"samsung\",\"01-01-2023\",1100000),\n",
    "(3,\"oneplus\",\"01-01-2023\",1100000),\n",
    "(1,\"iphone\",\"01-02-2023\",1300000),\n",
    "(2,\"samsung\",\"01-02-2023\",1120000),\n",
    "(3,\"oneplus\",\"01-02-2023\",1120000),\n",
    "(1,\"iphone\",\"01-03-2023\",1600000),\n",
    "(2,\"samsung\",\"01-03-2023\",1080000),\n",
    "(3,\"oneplus\",\"01-03-2023\",1160000),\n",
    "(1,\"iphone\",\"01-04-2023\",1700000),\n",
    "(2,\"samsung\",\"01-04-2023\",1800000),\n",
    "(3,\"oneplus\",\"01-04-2023\",1170000),\n",
    "(1,\"iphone\",\"01-05-2023\",1200000),\n",
    "(2,\"samsung\",\"01-05-2023\",980000),\n",
    "(3,\"oneplus\",\"01-05-2023\",1175000),\n",
    "(1,\"iphone\",\"01-06-2023\",1100000),\n",
    "(2,\"samsung\",\"01-06-2023\",1100000),\n",
    "(3,\"oneplus\",\"01-06-2023\",1200000)\n",
    "]\n",
    "emp_schema = [\"product_id\", \"product_name\", \"sales_date\", \"sales\"]\n",
    "prod_df = spark.createDataFrame(data=emp_data, schema=emp_schema)\n",
    "\n",
    "prod_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe6d526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy('product_id').orderBy('sales_date').rowsBetween(-2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fef53d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[product_id: bigint, product_name: string, sales_date: string, sales: string, running_row: double]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_df.withColumn(\"running_row\", sum('sales').over(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1099b5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbabcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3eb90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1353f2f9",
   "metadata": {},
   "source": [
    "# flatten nested json in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8316de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+--------------------+-------------+-------------+-------------+------+\n",
      "|code|message|         restaurants|results_found|results_shown|results_start|status|\n",
      "+----+-------+--------------------+-------------+-------------+-------------+------+\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|[{{{17066603}, b9...|         6835|           20|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|[{{{17093124}, b9...|         8680|           20|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|[{{{17580142}, b9...|          943|           20|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|[{{{17284158}, b9...|          257|           20|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|[{{{17678233}, b9...|          358|           20|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|[{{{17375047}, b9...|          641|           20|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|                  []|            0|            0|            1|  NULL|\n",
      "|NULL|   NULL|[{{{17616590}, b9...|         1613|           20|            1|  NULL|\n",
      "+----+-------+--------------------+-------------+-------------+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdf = spark.read.format('json')\\\n",
    "           .option('inferschema', True)\\\n",
    "           .option('multiline', True)\\\n",
    "           .load('resturant_json_data.json')\n",
    "jdf.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38449560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: long (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- restaurants: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- restaurant: struct (nullable = true)\n",
      " |    |    |    |-- R: struct (nullable = true)\n",
      " |    |    |    |    |-- res_id: long (nullable = true)\n",
      " |    |    |    |-- apikey: string (nullable = true)\n",
      " |    |    |    |-- average_cost_for_two: long (nullable = true)\n",
      " |    |    |    |-- cuisines: string (nullable = true)\n",
      " |    |    |    |-- currency: string (nullable = true)\n",
      " |    |    |    |-- deeplink: string (nullable = true)\n",
      " |    |    |    |-- establishment_types: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- events_url: string (nullable = true)\n",
      " |    |    |    |-- featured_image: string (nullable = true)\n",
      " |    |    |    |-- has_online_delivery: long (nullable = true)\n",
      " |    |    |    |-- has_table_booking: long (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- is_delivering_now: long (nullable = true)\n",
      " |    |    |    |-- location: struct (nullable = true)\n",
      " |    |    |    |    |-- address: string (nullable = true)\n",
      " |    |    |    |    |-- city: string (nullable = true)\n",
      " |    |    |    |    |-- city_id: long (nullable = true)\n",
      " |    |    |    |    |-- country_id: long (nullable = true)\n",
      " |    |    |    |    |-- latitude: string (nullable = true)\n",
      " |    |    |    |    |-- locality: string (nullable = true)\n",
      " |    |    |    |    |-- locality_verbose: string (nullable = true)\n",
      " |    |    |    |    |-- longitude: string (nullable = true)\n",
      " |    |    |    |    |-- zipcode: string (nullable = true)\n",
      " |    |    |    |-- menu_url: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- offers: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- photos_url: string (nullable = true)\n",
      " |    |    |    |-- price_range: long (nullable = true)\n",
      " |    |    |    |-- switch_to_order_menu: long (nullable = true)\n",
      " |    |    |    |-- thumb: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- user_rating: struct (nullable = true)\n",
      " |    |    |    |    |-- aggregate_rating: string (nullable = true)\n",
      " |    |    |    |    |-- rating_color: string (nullable = true)\n",
      " |    |    |    |    |-- rating_text: string (nullable = true)\n",
      " |    |    |    |    |-- votes: string (nullable = true)\n",
      " |-- results_found: long (nullable = true)\n",
      " |-- results_shown: long (nullable = true)\n",
      " |-- results_start: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44ff0da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: long (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- results_found: long (nullable = true)\n",
      " |-- results_shown: long (nullable = true)\n",
      " |-- results_start: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- new_restaurants: struct (nullable = true)\n",
      " |    |-- restaurant: struct (nullable = true)\n",
      " |    |    |-- R: struct (nullable = true)\n",
      " |    |    |    |-- res_id: long (nullable = true)\n",
      " |    |    |-- apikey: string (nullable = true)\n",
      " |    |    |-- average_cost_for_two: long (nullable = true)\n",
      " |    |    |-- cuisines: string (nullable = true)\n",
      " |    |    |-- currency: string (nullable = true)\n",
      " |    |    |-- deeplink: string (nullable = true)\n",
      " |    |    |-- establishment_types: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- events_url: string (nullable = true)\n",
      " |    |    |-- featured_image: string (nullable = true)\n",
      " |    |    |-- has_online_delivery: long (nullable = true)\n",
      " |    |    |-- has_table_booking: long (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- is_delivering_now: long (nullable = true)\n",
      " |    |    |-- location: struct (nullable = true)\n",
      " |    |    |    |-- address: string (nullable = true)\n",
      " |    |    |    |-- city: string (nullable = true)\n",
      " |    |    |    |-- city_id: long (nullable = true)\n",
      " |    |    |    |-- country_id: long (nullable = true)\n",
      " |    |    |    |-- latitude: string (nullable = true)\n",
      " |    |    |    |-- locality: string (nullable = true)\n",
      " |    |    |    |-- locality_verbose: string (nullable = true)\n",
      " |    |    |    |-- longitude: string (nullable = true)\n",
      " |    |    |    |-- zipcode: string (nullable = true)\n",
      " |    |    |-- menu_url: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- offers: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- photos_url: string (nullable = true)\n",
      " |    |    |-- price_range: long (nullable = true)\n",
      " |    |    |-- switch_to_order_menu: long (nullable = true)\n",
      " |    |    |-- thumb: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- user_rating: struct (nullable = true)\n",
      " |    |    |    |-- aggregate_rating: string (nullable = true)\n",
      " |    |    |    |-- rating_color: string (nullable = true)\n",
      " |    |    |    |-- rating_text: string (nullable = true)\n",
      " |    |    |    |-- votes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdf.select('*', explode('restaurants').alias('new_restaurants')).drop('restaurants').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4148f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|  res_id|\n",
      "+--------+\n",
      "|17066603|\n",
      "|17059541|\n",
      "|17064405|\n",
      "|17057797|\n",
      "|17057591|\n",
      "|17064266|\n",
      "|17060516|\n",
      "|17060320|\n",
      "|17059060|\n",
      "|17059012|\n",
      "|17060869|\n",
      "|17061231|\n",
      "|17058534|\n",
      "|17057925|\n",
      "|17064031|\n",
      "|17061237|\n",
      "|17061253|\n",
      "|17061296|\n",
      "|17061205|\n",
      "|17057397|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdf.select('*', explode('restaurants').alias('new_restaurants')).drop('restaurants')\\\n",
    "   .select('new_restaurants.restaurant.R.res_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b5d8d91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: long (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- results_found: long (nullable = true)\n",
      " |-- results_shown: long (nullable = true)\n",
      " |-- results_start: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- new_restaurants: struct (nullable = true)\n",
      " |    |-- restaurant: struct (nullable = true)\n",
      " |    |    |-- R: struct (nullable = true)\n",
      " |    |    |    |-- res_id: long (nullable = true)\n",
      " |    |    |-- apikey: string (nullable = true)\n",
      " |    |    |-- average_cost_for_two: long (nullable = true)\n",
      " |    |    |-- cuisines: string (nullable = true)\n",
      " |    |    |-- currency: string (nullable = true)\n",
      " |    |    |-- deeplink: string (nullable = true)\n",
      " |    |    |-- establishment_types: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- events_url: string (nullable = true)\n",
      " |    |    |-- featured_image: string (nullable = true)\n",
      " |    |    |-- has_online_delivery: long (nullable = true)\n",
      " |    |    |-- has_table_booking: long (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- is_delivering_now: long (nullable = true)\n",
      " |    |    |-- location: struct (nullable = true)\n",
      " |    |    |    |-- address: string (nullable = true)\n",
      " |    |    |    |-- city: string (nullable = true)\n",
      " |    |    |    |-- city_id: long (nullable = true)\n",
      " |    |    |    |-- country_id: long (nullable = true)\n",
      " |    |    |    |-- latitude: string (nullable = true)\n",
      " |    |    |    |-- locality: string (nullable = true)\n",
      " |    |    |    |-- locality_verbose: string (nullable = true)\n",
      " |    |    |    |-- longitude: string (nullable = true)\n",
      " |    |    |    |-- zipcode: string (nullable = true)\n",
      " |    |    |-- menu_url: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- offers: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- photos_url: string (nullable = true)\n",
      " |    |    |-- price_range: long (nullable = true)\n",
      " |    |    |-- switch_to_order_menu: long (nullable = true)\n",
      " |    |    |-- thumb: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- user_rating: struct (nullable = true)\n",
      " |    |    |    |-- aggregate_rating: string (nullable = true)\n",
      " |    |    |    |-- rating_color: string (nullable = true)\n",
      " |    |    |    |-- rating_text: string (nullable = true)\n",
      " |    |    |    |-- votes: string (nullable = true)\n",
      " |-- res_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdf.select('*', explode('restaurants').alias('new_restaurants')).drop('restaurants')\\\n",
    "   .select('*','new_restaurants.restaurant.R.res_id').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f51de37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------------+-------------+-------------+------+---------------+------+-----------------------+----+\n",
      "|code|message|results_found|results_shown|results_start|status|new_restaurants|res_id|establishment_types_new|name|\n",
      "+----+-------+-------------+-------------+-------------+------+---------------+------+-----------------------+----+\n",
      "+----+-------+-------------+-------------+-------------+------+---------------+------+-----------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdf.select('*', explode('restaurants').alias('new_restaurants')).drop('restaurants')\\\n",
    "   .select('*','new_restaurants.restaurant.R.res_id', \n",
    "                explode('new_restaurants.restaurant.establishment_types').alias('establishment_types_new')\n",
    "                ,'new_restaurants.restaurant.name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf68576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode = will remove null records \n",
    "# explode_outer = will show all records including null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "841bc653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------+------------------------------------+\n",
      "|res_id  |establishment_types_new|name                                |\n",
      "+--------+-----------------------+------------------------------------+\n",
      "|17066603|NULL                   |The Coop                            |\n",
      "|17059541|NULL                   |Maggiano's Little Italy             |\n",
      "|17064405|NULL                   |Tako Cheena by Pom Pom              |\n",
      "|17057797|NULL                   |Bosphorous Turkish Cuisine          |\n",
      "|17057591|NULL                   |Bahama Breeze Island Grille         |\n",
      "|17064266|NULL                   |Hawkers Asian Street Fare           |\n",
      "|17060516|NULL                   |Seasons 52 Fresh Grill              |\n",
      "|17060320|NULL                   |Raglan Road Irish Pub and Restaurant|\n",
      "|17059060|NULL                   |Hillstone                           |\n",
      "|17059012|NULL                   |Hollerbach's Willow Tree Café       |\n",
      "|17060869|NULL                   |Texas de Brazil                     |\n",
      "|17061231|NULL                   |The Ravenous Pig                    |\n",
      "|17058534|NULL                   |Earl of Sandwich                    |\n",
      "|17057925|NULL                   |Café Tu Tu Tango                    |\n",
      "|17064031|NULL                   |Tibby's New Orleans Kitchen         |\n",
      "|17061237|NULL                   |Cevíche Tapas Bar & Restaurant      |\n",
      "|17061253|NULL                   |Ethos Vegan Kitchen                 |\n",
      "|17061296|NULL                   |Pom Pom's Teahouse and Sandwicheria |\n",
      "|17061205|NULL                   |Yellow Dog Eats                     |\n",
      "|17057397|NULL                   |'Ohana                              |\n",
      "+--------+-----------------------+------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdf.select('*', explode('restaurants').alias('new_restaurants')).drop('restaurants')\\\n",
    "   .select('*','new_restaurants.restaurant.R.res_id', \n",
    "                explode_outer('new_restaurants.restaurant.establishment_types').alias('establishment_types_new')\n",
    "                ,'new_restaurants.restaurant.name').drop('new_restaurants','code','message','results_found','results_shown',\\\n",
    "                                                        'results_start','status').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d80e768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af78db6c",
   "metadata": {},
   "source": [
    "# SCD2 (slowly changing dimension2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed32be4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------+------+--------------------+------------------+\n",
      "| id|  name|   city|country|active|effective_start_date|effective_end_date|\n",
      "+---+------+-------+-------+------+--------------------+------------------+\n",
      "|  1|manish|  arwal|  india|     N|          2022-09-15|        2022-09-25|\n",
      "|  2|vikash|  patna|  india|     Y|          2023-08-12|              NULL|\n",
      "|  3|nikita|  delhi|  india|     Y|          2023-09-10|              NULL|\n",
      "|  4|rakesh| jaipur|  india|     Y|          2023-06-10|              NULL|\n",
      "|  5| ayush|     NY|    USA|     Y|          2023-06-10|              NULL|\n",
      "|  1|manish|gurgaon|  india|     Y|          2022-09-25|              NULL|\n",
      "+---+------+-------+-------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_dim_data = [\n",
    "(1,'manish','arwal','india','N','2022-09-15','2022-09-25'),\n",
    "(2,'vikash','patna','india','Y','2023-08-12',None),\n",
    "(3,'nikita','delhi','india','Y','2023-09-10',None),\n",
    "(4,'rakesh','jaipur','india','Y','2023-06-10',None),\n",
    "(5,'ayush','NY','USA','Y','2023-06-10',None),\n",
    "(1,'manish','gurgaon','india','Y','2022-09-25',None),\n",
    "]\n",
    "\n",
    "customer_schema= ['id','name','city','country','active','effective_start_date','effective_end_date']\n",
    "\n",
    "customer_dim_df = spark.createDataFrame(data= customer_dim_data,schema=customer_schema)\n",
    "customer_dim_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "47c2d25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "|sales_id|customer_id|customer_name|sales_date|food_delivery_address|food_delivery_country|food_cost|\n",
      "+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "|       1|          1|       manish|2023-01-16|              gurgaon|                india|      380|\n",
      "|      77|          1|       manish|2023-03-11|            bangalore|                india|      300|\n",
      "|      12|          3|       nikita|2023-09-20|                delhi|                india|      127|\n",
      "|      54|          4|       rakesh|2023-08-10|               jaipur|                india|      321|\n",
      "|      65|          5|        ayush|2023-09-07|                mosco|               russia|      765|\n",
      "|      89|          6|        rajat|2023-08-10|               jaipur|                india|      321|\n",
      "+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_data = [\n",
    "\n",
    "(1,1,'manish','2023-01-16','gurgaon','india',380),\n",
    "(77,1,'manish','2023-03-11','bangalore','india',300),\n",
    "(12,3,'nikita','2023-09-20','delhi','india',127),\n",
    "(54,4,'rakesh','2023-08-10','jaipur','india',321),\n",
    "(65,5,'ayush','2023-09-07','mosco','russia',765),\n",
    "(89,6,'rajat','2023-08-10','jaipur','india',321)\n",
    "]\n",
    "\n",
    "sales_schema = ['sales_id', 'customer_id','customer_name', 'sales_date', 'food_delivery_address','food_delivery_country', 'food_cost']\n",
    "\n",
    "sales_df = spark.createDataFrame(data=sales_data,schema=sales_schema)\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "327dee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data = customer_dim_df.join(sales_df, customer_dim_df['id'] == sales_df['customer_id'], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "39eb1baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------+------+--------------------+------------------+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "| id|  name|   city|country|active|effective_start_date|effective_end_date|sales_id|customer_id|customer_name|sales_date|food_delivery_address|food_delivery_country|food_cost|\n",
      "+---+------+-------+-------+------+--------------------+------------------+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "|  1|manish|  arwal|  india|     N|          2022-09-15|        2022-09-25|      77|          1|       manish|2023-03-11|            bangalore|                india|      300|\n",
      "|  1|manish|  arwal|  india|     N|          2022-09-15|        2022-09-25|       1|          1|       manish|2023-01-16|              gurgaon|                india|      380|\n",
      "|  2|vikash|  patna|  india|     Y|          2023-08-12|              NULL|    NULL|       NULL|         NULL|      NULL|                 NULL|                 NULL|     NULL|\n",
      "|  3|nikita|  delhi|  india|     Y|          2023-09-10|              NULL|      12|          3|       nikita|2023-09-20|                delhi|                india|      127|\n",
      "|  4|rakesh| jaipur|  india|     Y|          2023-06-10|              NULL|      54|          4|       rakesh|2023-08-10|               jaipur|                india|      321|\n",
      "|  5| ayush|     NY|    USA|     Y|          2023-06-10|              NULL|      65|          5|        ayush|2023-09-07|                mosco|               russia|      765|\n",
      "|  1|manish|gurgaon|  india|     Y|          2022-09-25|              NULL|      77|          1|       manish|2023-03-11|            bangalore|                india|      300|\n",
      "|  1|manish|gurgaon|  india|     Y|          2022-09-25|              NULL|       1|          1|       manish|2023-01-16|              gurgaon|                india|      380|\n",
      "+---+------+-------+-------+------+--------------------+------------------+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff9011d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify changes in address and create new records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a7878a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------+---------------------+------+--------------------+------------------+\n",
      "|customer_id|customer_name|     city|food_delivery_country|active|effective_start_date|effective_end_date|\n",
      "+-----------+-------------+---------+---------------------+------+--------------------+------------------+\n",
      "|          1|       manish|bangalore|                india|     Y|          2023-03-11|              NULL|\n",
      "|          5|        ayush|    mosco|               russia|     Y|          2023-09-07|              NULL|\n",
      "+-----------+-------------+---------+---------------------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_records_df = joined_data.where(\n",
    "                   (col('food_delivery_address') != col('city')) & (col('active') == 'Y'))\\\n",
    "                 .withColumn('active', lit('Y'))\\\n",
    "                 .withColumn('effective_start_date', col('sales_date'))\\\n",
    "                 .withColumn('effective_end_date', lit(None))\\\n",
    "                 .select('customer_id','customer_name',\n",
    "                        col('food_delivery_address').alias('city'),\n",
    "                        'food_delivery_country','active', 'effective_start_date','effective_end_date')\n",
    "new_records_df.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3f5426c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update old records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "25281385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------------+------+--------------------+------------------+\n",
      "|customer_id|customer_name|   city|food_delivery_country|active|effective_start_date|effective_end_date|\n",
      "+-----------+-------------+-------+---------------------+------+--------------------+------------------+\n",
      "|          1|       manish|gurgaon|                india|     N|          2022-09-25|        2023-03-11|\n",
      "|          5|        ayush|     NY|               russia|     N|          2023-06-10|        2023-09-07|\n",
      "+-----------+-------------+-------+---------------------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "old_records = joined_data.where(\n",
    "                   (col('food_delivery_address') != col('city')) & (col('active') == 'Y'))\\\n",
    "                 .withColumn('active', lit('N'))\\\n",
    "                 .withColumn('effective_end_date', col('sales_date'))\\\n",
    "                 .select('customer_id',\n",
    "                         'customer_name',\n",
    "                         'city',\n",
    "                         'food_delivery_country',\n",
    "                         'active', \n",
    "                         'effective_start_date',\n",
    "                         'effective_end_date')\n",
    "old_records.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6bdda3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out new customers and insert them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "33845096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------------+---------------------+------+--------------------+------------------+\n",
      "|customer_id|customer_name|food_delivery_address|food_delivery_country|active|effective_start_date|effective_end_date|\n",
      "+-----------+-------------+---------------------+---------------------+------+--------------------+------------------+\n",
      "|          6|        rajat|               jaipur|                india|     Y|          2023-08-10|              NULL|\n",
      "+-----------+-------------+---------------------+---------------------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_customers = sales_df.join(customer_dim_df, sales_df['customer_id'] == customer_dim_df['id'], 'leftanti')\\\n",
    "                 .withColumn('active', lit('Y'))\\\n",
    "                 .withColumn('effective_start_date', col('sales_date'))\\\n",
    "                 .withColumn('effective_end_date', lit(None))\\\n",
    "                 .select('customer_id','customer_name',\n",
    "                         'food_delivery_address',\n",
    "                         'food_delivery_country',\n",
    "                         'active', \n",
    "                         'effective_start_date',\n",
    "                         'effective_end_date')\n",
    "new_customers.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "98f2d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all df in one df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8572372c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "| id|  name|     city|country|active|effective_start_date|effective_end_date|\n",
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "|  1|manish|    arwal|  india|     N|          2022-09-15|        2022-09-25|\n",
      "|  2|vikash|    patna|  india|     Y|          2023-08-12|              NULL|\n",
      "|  3|nikita|    delhi|  india|     Y|          2023-09-10|              NULL|\n",
      "|  4|rakesh|   jaipur|  india|     Y|          2023-06-10|              NULL|\n",
      "|  5| ayush|       NY|    USA|     Y|          2023-06-10|              NULL|\n",
      "|  1|manish|  gurgaon|  india|     Y|          2022-09-25|              NULL|\n",
      "|  1|manish|bangalore|  india|     Y|          2023-03-11|              NULL|\n",
      "|  5| ayush|    mosco| russia|     Y|          2023-09-07|              NULL|\n",
      "|  1|manish|  gurgaon|  india|     N|          2022-09-25|        2023-03-11|\n",
      "|  5| ayush|       NY| russia|     N|          2023-06-10|        2023-09-07|\n",
      "|  6| rajat|   jaipur|  india|     Y|          2023-08-10|              NULL|\n",
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_records = customer_dim_df.union(new_records_df).union(old_records).union(new_customers)\n",
    "final_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ad92aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "98e8b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy('id','active').orderBy(col('effective_start_date').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "585986b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "| id|  name|     city|country|active|effective_start_date|effective_end_date|\n",
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "|  1|manish|  gurgaon|  india|     N|          2022-09-25|        2023-03-11|\n",
      "|  1|manish|    arwal|  india|     N|          2022-09-15|        2022-09-25|\n",
      "|  1|manish|bangalore|  india|     Y|          2023-03-11|              NULL|\n",
      "|  2|vikash|    patna|  india|     Y|          2023-08-12|              NULL|\n",
      "|  3|nikita|    delhi|  india|     Y|          2023-09-10|              NULL|\n",
      "|  4|rakesh|   jaipur|  india|     Y|          2023-06-10|              NULL|\n",
      "|  5| ayush|       NY| russia|     N|          2023-06-10|        2023-09-07|\n",
      "|  5| ayush|    mosco| russia|     Y|          2023-09-07|              NULL|\n",
      "|  6| rajat|   jaipur|  india|     Y|          2023-08-10|              NULL|\n",
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_records.withColumn('rnk', rank().over(window))\\\n",
    "             .filter(~((col('active')=='Y')&(col('rnk')>=2))).drop('rnk').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ee503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
