API - Applicatin programming interface
REST API - Represntational state transfer
post-create
get - read 
put - update 
delete - delete 


Hadoop is an open source framework that allows us to store & process large dta sets in a parallel & distributed manner. 
Node = 128 MB 
Two main components HDFS (Hadoop distributed file system is the primry data storage system used by hadoop applications) & MapReduce (used for processing).
Name Node (Master node, it stores metadata (data related information), Data Node(slave node).
It has 3 replicatin factor for fault tolerance.
Rack is a physical collection of various nodes, generally 30-40 nodes under one rack.
YARN = manage resource, schedule jobs 

Yarn is comprised of Resource Manager and Node Manager. There is only one Resource Manager which runs on Master Node. There will be multiple Node Managers running on each Data Node. Resource Manager deals with resource management to execute any Job/Application.

https://stackoverflow.com/questions/30967247/difference-between-application-manager-and-application-master-in-yarn#:~:text=Yarn%20is%20comprised%20of%20Resource,to%20execute%20any%20Job%2FApplication 

1) How will you measure HDFS space consumed?
The two popular utilities or commands to measure HDFS space consumed are hdfs dfs –du and hdfs dfsadmin –report. 
HDFS provides reliable storage by copying data to multiple nodes. The number of copies it creates is usually referred to as the replication factor which is greater than one.
hdfs dfs –du –This command shows the space consumed by data without replications.
hdfs dfsadmin –report- This command shows the real disk usage by considering data replication.


2) Is it a good practice to use HDFS for multiple small files?
It is not a good practice to use HDFS for multiple small files because NameNode is an expensive high performance system. Occupying the NameNode space with the unnecessary amount of metadata generated for each of the small multiple files is not sensible. If there is a large file with loads of data, then it is always a wise move to use HDFS because it will occupy less space for metadata and provide optimized performance.

3) I have a file “Sample” on HDFS. How can I copy this file to the local file system?
This can be accomplished using the following command -
bin/hadoop fs -copyToLocal /hdfs/source/path /localfs/destination/path


4) What do you understand by Inodes?
HDFS namespace consists of files and directories. Inodes are used to represent these files and directories on the NameNode. Inodes record various attributes like the namespace quota, disk space quota, permissions, modified time and access time.

5) Replication causes data redundancy then why is it still preferred in HDFS?
As we know that Hadoop works on commodity hardware, so there is an increased probability of getting crashed. Thus to make the entire Hadoop system highly tolerant, replication factor is preferred even though it creates multiple copies of the same data at different locations. Data on HDFS is stored in at least 3 different locations. Whenever one copy of the data is corrupted and the other copy of the data is not available due to some technical glitches then the data can be accessed from the third location without any data loss.

8) Data is replicated at least thrice on HDFS. Does it imply that any alterations or calculations done on one copy of the data will be reflected in the other two copies also?
Calculations or any transformations are performed on the original data and do not get reflected to all the copies of data. Master node identifies where the original data is located and performs the calculations. Only if the node is not responding or data is corrupted then it will perform the desired calculations on the second replica.


9) What do you understand by Active and Passive NameNodes?

The NameNode that works and runs in the Hadoop cluster is often referred to as the Active NameNode. Passive NameNode also known as Standby NameNode is the similar to an active NameNode but it comes into action only when the active NameNode fails. Whenever the active NameNode fails, the passive NameNode or the standby NameNode replaces the active NameNode, to ensure that the Hadoop cluster is never without a NameNode.

10) How will you balance the disk space usage on a HDFS cluster?

Balancer tool helps achieve this by taking a threshold value as input parameter which is always a fraction between 0 and 1. The HDFS cluster is said to be balanced, if, for every DataNode, the ratio of used space at the node to total capacity of the node differs from the ratio of used space in the cluster to total capacity of the cluster - is not greater than the threshold value.





