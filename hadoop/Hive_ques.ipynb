{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb79626d",
   "metadata": {},
   "source": [
    "# HIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be3ab8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d2bcf6b",
   "metadata": {},
   "source": [
    "##  Apache Hive – A Brief Introduction\n",
    "\n",
    "Apache Hive is a data warehouse system built on top of Hadoop and is used for analyzing structured and semi-structured data. It provides a mechanism to project structure onto the data and perform queries written in HQL (Hive Query Language) that are similar to SQL statements. Internally, these queries or HQL gets converted to map reduce jobs by the Hive compiler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51337e3",
   "metadata": {},
   "source": [
    "## HBase\t\n",
    "Apache HBase is an open-source, NoSQL database that stores and manages large amounts of data in real time. It's a column-oriented database that's well-suited for big data use cases, such as real-time data processing and random access to large data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6640446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb4ba755",
   "metadata": {},
   "source": [
    "## Why Hive does not store metadata information in HDFS?\n",
    "\n",
    "Hive stores metadata information in the metastore using RDBMS instead of HDFS. The reason for choosing RDBMS is to achieve low latency as HDFS read/write operations are time consuming processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c06697",
   "metadata": {},
   "source": [
    "## What is the difference between external table and managed (internal) table?\n",
    "\n",
    "1. In case of managed table, If one drops a managed table, the metadata information along with the table data is deleted from the Hive warehouse directory.\n",
    "2. On the contrary, in case of an external table, Hive just deletes the metadata information regarding the table and leaves the table data present in HDFS untouched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d9710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8758bb9",
   "metadata": {},
   "source": [
    "## When should we use SORT BY instead of ORDER BY?\n",
    "\n",
    "We should use SORT BY instead of ORDER BY when we have to sort huge datasets because SORT BY clause sorts the data using multiple reducers whereas ORDER BY sorts all of the data together using a single reducer. Therefore, using ORDER BY against a large number of inputs will take a lot of time to execute. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a0583",
   "metadata": {},
   "source": [
    "## What is a partition in Hive?\n",
    "\n",
    "Hive organizes tables into partitions for grouping similar type of data together based on a column or partition key. Each Table can have one or more partition keys to identify a particular partition. Physically, a partition is nothing but a sub-directory in the table directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2e921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33c5cb13",
   "metadata": {},
   "source": [
    "## Why do we perform partitioning in Hive?\n",
    "\n",
    "Partitioning provides granularity in a Hive table and therefore, reduces the query latency by scanning only relevant partitioned data instead of the whole data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8483b7d4",
   "metadata": {},
   "source": [
    "## Why do we need buckets?\n",
    "\n",
    "1. Bucketing makes the sampling process more efficient and therefore, allows us to decrease the query time.\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596c64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a88bf7c",
   "metadata": {},
   "source": [
    "## What is the schema evolution in hive ?\n",
    "\n",
    "Schema evolution in Apache Hive refers to the ability to modify the structure of existing tables without losing existing data. It allows users to alter the schema of tables to accommodate changes in data requirements or to optimize data storage and processing. Schema evolution in Hive primarily involves adding, dropping, or renaming columns, as well as changing column data types.\n",
    "\n",
    "Hive supports schema evolution through the following mechanisms:\n",
    "\n",
    "1. Addition of Columns: ALTER TABLE my_table COLUMN age int;\n",
    "2. Dropping Columns: ALTER TABLE my_table DROP COLUMN age;\n",
    "3. RENAMING Columns: ALTER TABLE my_table CHANGE COLUMN col_name co_n STRING;\n",
    "4. CHANGING Columns Data Types: ALTER TABLE my_table CHANGE COLUMN age age INT;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e739c3f",
   "metadata": {},
   "source": [
    "## What is the difference between bucketing and partition?\n",
    "\n",
    "A concise comparison:\n",
    "\n",
    "1) Partitioning: Divides data into logical sections based on column values, creating separate directories for each section. Helps improve query performance by accessing only relevant partitions.\n",
    "2) Bucketing: Divides data into fixed-size buckets based on hash values, grouping similar data together. Used to evenly distribute data within partitions and optimize operations like sampling, joins, and aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee233ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "009f830a",
   "metadata": {},
   "source": [
    "## Can you explain Sort By, Distribute By, Order By and Cluster By in Hive?\n",
    "\n",
    "In Hive, these clauses are used for organizing data during query execution:\n",
    "\n",
    "1. Sort By:\n",
    "\n",
    "SORT BY is used to sort the data within each reducer before writing the output.\n",
    "It does not guarantee a total order across all the records but sorts data within each reducer.\n",
    "It’s useful when you need sorted output but don’t require a globally sorted result.\n",
    "Example: SELECT * FROM table SORT BY column1;\n",
    "\n",
    "2. Distribute By:\n",
    "\n",
    "DISTRIBUTE BY is used to distribute data to reducers based on a specific column or expression.\n",
    "It ensures that rows with the same value for the distribution column are sent to the same reducer.\n",
    "It’s commonly used in conjunction with SORT BY to control data distribution and sorting.\n",
    "Example: SELECT * FROM table DISTRIBUTE BY column1;\n",
    "\n",
    "3. Order By:\n",
    "\n",
    "ORDER BY is used to globally sort the output based on one or more columns.\n",
    "It guarantees a total order across all the records but can be less efficient than SORT BY.\n",
    "It sorts data across all reducers, which may require a shuffle operation.\n",
    "Example: SELECT * FROM table ORDER BY column1;\n",
    "\n",
    "4. Cluster By:\n",
    "\n",
    "CLUSTER BY is a combination of DISTRIBUTE BY and SORT BY.\n",
    "It first distributes the data to reducers based on the specified column, similar to DISTRIBUTE BY.\n",
    "Then, within each reducer, it sorts the data based on the same column, similar to SORT BY.\n",
    "It’s often used for efficient sorting and data distribution.\n",
    "Example: SELECT * FROM table CLUSTER BY column1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73f353",
   "metadata": {},
   "source": [
    "## Can we use Hive for Online Transaction Processing (OLTP) systems?\n",
    "\n",
    "Hive is not suitable for OLTP due to its batch processing nature and high query latency. For OLTP systems, databases like HBase, Cassandra, or relational databases are preferred. These databases offer low-latency, high-concurrency transaction processing capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8dba85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5b8f6e4",
   "metadata": {},
   "source": [
    "## What is Metastore in Hive?\n",
    "\n",
    "The Metastore in Hive is a central repository that stores metadata information about Hive tables, partitions, columns, data types, and storage location. It helps in managing and organizing Hive metadata, allowing users to query and access data efficiently using HiveQL. The Metastore can use different backends such as an embedded Derby database, MySQL, or PostgreSQL to store metadata information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0205b179",
   "metadata": {},
   "source": [
    "## What is SerDe in Hive?\n",
    "\n",
    "SerDe, short for Serializer/Deserializer, is a crucial component in Hive that facilitates the serialization and deserialization of data between the Hive table’s internal representation and external formats. It enables Hive to work with various file formats and data structures by defining how data should be serialized when written to storage and deserialized when read back into Hive. Users can specify custom SerDe implementations or use built-in SerDe libraries to work with different data formats like JSON, CSV, Avro, or custom binary formats in Hive tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be96817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3354133",
   "metadata": {},
   "source": [
    "## What are the components in Hive data model?\n",
    "\n",
    "The components in the Hive data model include:\n",
    "\n",
    "1. Tables: Represent structured data collections in Hive, organized into rows and columns.\n",
    "2. Partitions: Allow data within tables to be divided into subsets based on specific criteria, improving query performance and data organization.\n",
    "3. Buckets (or Clusters): Further divide data within partitions into smaller, more manageable units based on hashing or sorting algorithms, enhancing query efficiency.\n",
    "4. Views: Virtual tables generated from SQL queries, providing a convenient way to access subsets of data or complex transformations without duplicating the underlying data.\n",
    "5. SerDe: Serializer/Deserializer responsible for converting data between Hive’s internal representation and external formats, enabling compatibility with various file formats and data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4725464",
   "metadata": {},
   "source": [
    "## What are the main components of Hive?\n",
    "\n",
    "The main components of Hive are as follows:\n",
    "\n",
    "1. Hive Driver: Receives queries from users, handles sessions, and provides commands to execute and fetch APIs similar to JDBC/ODBC interface.\n",
    "2. Metastore: Stores all metadata information about Hive tables, partitions, columns, and column types. It manages serializers and deserializers used in reading and writing data to corresponding HDFS files.\n",
    "3. Hive Compiler: Parses queries, performs semantic analysis on query blocks and expressions, and generates execution plans for accessing data from tables and partitions.\n",
    "4. Execution Engine: Executes the execution plan generated by the compiler, managing dependencies between different stages and executing them on relevant system components.\n",
    "5. User Interface (UI): Provides a UI for users to interact with the system, allowing them to submit queries and perform other operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74981498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "405924e2",
   "metadata": {},
   "source": [
    "## Can we create multiple tables in Hive for a data file?\n",
    "\n",
    "Yes, you can create multiple tables in Hive for a single data file by defining different schemas or views over the same underlying data. This is often done using different table definitions with different column selections, partitions, or storage formats. Alternatively, you can create views on top of the data file to provide different perspectives or subsets of the data without duplicating the underlying storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ced695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
